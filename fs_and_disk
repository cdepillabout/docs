
###################
###### BTRFS ######
###################

### TODO: The below is a work in progress while taking notes from 
###    http://blog.fabio.mancinelli.me/2012/12/28/Arch_Linux_on_BTRFS.html
### There are also good resources on the Arch Linux website
###    https://wiki.archlinux.org/index.php/Btrfs
### Here is some more from the btrfs site itself
###    https://btrfs.wiki.kernel.org/index.php/Getting_started
### Here is another intro page
###    http://www.funtoo.org/wiki/BTRFS_Fun

# A BTRFS-formatted partition contains by default a single subvolume where
# users can store files. A subvolume can be thought as an independent
# filesystem that is attached to some parent (another subvolume).

# The interesting thing is that subvolumes can be mounted as root filesystems.
# When this is the case, users can only “see” what is inside the subvolume and
# not what is contained in the parent subvolume. Only by mounting the toplevel
# subvolume you can have access to all the data stored in a BTRFS filesystem.

# Subvolumes appear as directories in the filesystem hierarchy. You can
# distinguish between them and "vanilla" directories by using the 
# `btrfs subvolume list` command.

# Another interesting thing about subvolumes is that they can be snapshotted. A
# snapshot is an exact copy of a subvolume that has an independent life. A
# snapshot uses a copy-on-write policy which makes snapshots quite
# space-efficient. The initial snapshot, in fact, doesn’t take any additional
# space. Only what is modified is then copied and starts to occupy actual disk
# space.  Snapshots can be writable and are actually subvolumes that can be
# used as such.

# Snapshots and subvolumes can be renamed and moved using the standard mv
# command. They can also be deleted using the rm -rf command (like if they were
# standard directories), but a more efficient way to do it is by using the
# btrfs subvolume delete command.

# When mounting a subvolume, all the child-subvolumes are recursively mounted
# as well. However snapshotting is not recursive. So when you take a snapshot
# of a subvolume X that has a child Y, only X is snapshotted.

# create btrfs partition
mkfs.btrfs -L "My Partition Label" /dev/sda1

# Mount btrfs partition and create default subvolume, in which we will create
# the directories __snapshot/ and __current/.  In current/ we will create subvolumes
# for the root filesystem, along with /home, /opt, and /var.
#
# The __snapshot and __current directories are created in the top-level
# subvolume of the BTRFS partition, and are used to distinguish between the
# subvolumes that are snapshots and those that are currently used as active
# subvolumes.
mount /dev/sda1 /mnt/mybtrfs
mkdir -p /mnt/btrfs/__snapshot # this is where our snapshots will get held
mkdir -p /mnt/btrfs/__current # this is where we will actually hold root, home, opt, var.
btrfs subvolume create /mnt/btrfs-root/__current/ROOT
btrfs subvolume create /mnt/btrfs-root/__current/home
btrfs subvolume create /mnt/btrfs-root/__current/opt
btrfs subvolume create /mnt/btrfs-root/__current/var

# list the subvolumes
btrfs subvolume list -p /mnt/btrfs-root/

# show the space taken up by files on the volume
btrfs filesystem df /mnt/btrfs-root

# mount root
mount -o defaults,relatimessd,nodev,subvol=__current/ROOT /dev/sda1 /mnt/btrfs-current

# Make a snapshot of root (this won't backup home, opt, and var, even if they are
# mounted underneath ROOT, because making snapshots of subvolumes is not recursive).
btrfs subvolume snapshot -r btrfs-root/__current/ROOT btrfs-root/__snapshot/ROOT@SOMEDATE

# This is how to roll back to an old snapshot.  First we get rid of our current root,
# then we use the snapshot command again to copy the snapshot back to ROOT, and finally
# we reboot. After rebooting we could even delete the ROOT.old folder.
mv btrfs-root/__current/ROOT btrfs-root/__current/ROOT.old
btrfs subvolume snapshot btrf-root/__snapshot/ROOT@SOMEDATE btrfs-root/__current/ROOT
reboot

# CoW comes with some advantages, but can negatively affect performance with
# large files that have small random writes. It is recommended to disable CoW
# for database files and virtual machine images. You can disable CoW for the
# entire block device by mounting it with "nodatacow" option. However, this
# will disable CoW for the entire file system.To disable CoW for single
# files/directories do:
chattr +C /path/to/some/file

# Likewise, to save space by forcing CoW when copying files use:
cp --reflink source dest 


# There are also a lot of options that you can play with to use multiple
# devices with btrfs.
# https://btrfs.wiki.kernel.org/index.php/Using_Btrfs_with_Multiple_Devices

# Create a filesystem across four drives (metadata mirrored, data striped)
mkfs.btrfs /dev/sdb /dev/sdc /dev/sdd /dev/sde
# Stripe the metadata without mirroring
mkfs.btrfs -m raid0 /dev/sdb /dev/sdc
# Use raid10 for both data and metadata
mkfs.btrfs -m raid10 -d raid10 /dev/sdb /dev/sdc /dev/sdd /dev/sde
# Don't duplicate metadata on a single drive
mkfs.btrfs -m single /dev/sdb
# Once you create a multi-device filesystem, you can use any device in the FS
# for the mount command:
mkfs.btrfs /dev/sdb /dev/sdc /dev/sde
mount /dev/sde /mnt
# There are also commands to add devices to currently mounted filesystems in order
# to increase space, do RAIDing, etc.



##############################
########### LVM ##############
##############################

# The basic building blocks of LVM.
#
#   Physical volume (PV): Partition on hard disk (or even hard disk itself or
#                         loopback file) on which you can have volume groups.
#                         It has a special header and is divided into physical
#                         extents. Think of physical volumes as big building
#                         blocks which can be used to build your hard drive.
#                         This would be something like an actual /dev/sda2 
#                         device.
#
#   Volume group (VG): Group of physical volumes that are used as storage
#                      volume (as one disk). They contain logical volumes.
#                      Think of volume groups as virtual hard drives.
#
#   Logical volume (LV): A "virtual/logical partition" that resides in a volume
#                        group and is composed of physical extents. Think of
#                        logical volumes as virtual partitions.
#
#   Physical extent (PE): A small part of a disk (usually 4MB) that can be
#						  assigned to a logical Volume. Think of physical
#						  extents as parts of disks that can be allocated to
#						  any partition. 

# Create the partion where your pv will reside.  Set the partion type to 'Linux LVM'.
cfdisk /dev/sda


##### Physical volumes

# Create a physical volume on the disks you want to use. If you have one disk
# it is best to just create one PV in one large partition. If you have multiple
# disks you can create partitions on each of them and create a PV on each
# partition. 
pvcreate /dev/sda2
pvcreate /dev/sdb

# Show physical volumes.
pvdisplay

# List all physical volumes on the system.
pvscan


##### Volume Groups

# Create a volume group on a physical volume.  First you need to create a
# volume group on one of the new partitions and then add to it all other
# physical volumes you want to have in it.  You can create more than 
# one volume group if you want to, but you will not have all your storage
# presented as one disk.
vgcreate VolGroup00 /dev/sda2
vgextend VolGroup00 /dev/sdb

# Show volume groups.
vgdisplay

# List all volume groups on the system. This may be needed after running 
# lvcreate if the devices don't automatically show up in /dev.
vgscan
# This will automatically activate everything.
vgchange --activate y


#### Logical Volumes

# Create the logical volumes on this volume group. These lvcreate commands
# are what will actually create /dev/VolGroup00 and /dev/mapper/* and /dev/dm-*.
lvcreate --size 10G --name lvolhome VolGroup00

# This creates a swap device. --contiguous means that this swap device will
# not get partitioned over one or more disks.
lvcreate --contiguous yes --size 10G --name lvolswap VolGroup00

# This fills all the remaining free space on the volume group.
lvcreate --extents +100%FREE --name lvolmedia VolGroup00

# Show created logical volumes.
lvdisplay

# List logical volumes.
lvscan

# Another command to list logical volumes.
lvs

# Now you can create filesystems on your logical volumes.
mkfs.ext4 /dev/mapper/VolGroup00-lvolhome
mkfs.ext4 /dev/mapper/VolGroup00-lvolmedia

# To grow a logical volume you first need to grow the logical volume and then
# the filesystem to use the newly created free space. 
lvextend --size 20G /dev/mapper/VolGroup00-lvhome
resize2fs /dev/mapper/VolGroup00-lvhome

# You can use this command to fill all free space on a volume group.
lvextend -l +100%FREE /dev/mapper/VolGroup00/lvolhome

# In order to shrink a logical volume, you first need to shrink the filesystem
# first and then shrink the logical volume. We shrink the filesystem more than
# needed so that when we shrink the logical volume we do not accidentally cut
# off the end of the filesystem. After that we grow the filesystem to fill all
# free space left on logical volume. 
resize2fs /dev/mapper/VolGroup00-lvolhome 4G
lvreduce --size 5G /dev/mapper/VolGroup00-lvolhome
resize2fs /dev/mapper/VolGroup00-lvolhome

# Make a snapshot of /home. Snapshots
# provide a 'frozen image' of the contents of the origin while the origin can
# still be updated. They enable  consistent  backups  and  online recovery of
# removed/overwritten data/files. The snapshot with the specified size
# does not need the same amount of storage the  origin  has.  In a typical
# scenario, 15-20% might be enough.  In case the snapshot runs out of storage,
# use lvextend(8) to grow it. Shrinking a snapshot  is  supported  by
# lvreduce(8)  as  well. Run lvdisplay(8) on the snapshot in order to check how
# much data is allocated to it.
lvcreate --size 2G --name homesnapshot --snapshot /dev/mapper/VolGroup00-lvolhome



############################
#### LOOPBACK DEVICE #######
############################

# check which loop devices are already being used
losetup -a

# make a file accessible from a loop device
# (--find will find the first available loop device, and if you pass in a 
# file name after it, it will automatically make that file into a loop device
# for you)
dd if=/dev/zero of=~/file.img bs=1MiB count=10
losetup --find --show ~/file.img

# now you can use it like a normal device
mkfs -t ext2 /dev/loop0
mount /dev/loop0 /mnt
umount /dev/loop0
losetup --detach /dev/loop0



################################
####### dm-crypt and LUKS ######
################################

# Things to keep in mind:
#
#   ATTENTION: By far the most questions on the cryptsetup mailing list are
#              from people that managed to damage the start of their LUKS
#              partitions, i.e. the LUKS header. In most cases, there is
#              nothing that can be done to help these poor souls recover their
#              data. Make sure you understand the problem and limitations
#              imposed by the LUKS security model BEFORE you face such a
#              disaster! In particular, make sure you have a current header
#              backup before doing any potentially dangerous operations.
#
#   CLONING/IMAGING: If you clone or image a LUKS container, you make a copy of
#                    the LUKS header and the master key will stay the same!
#                    That means that if you distribute an image to several
#                    machines, the same master key will be used on all of them,
#                    regardless of whether you change the passphrases. Do NOT
#                    do this! If you do, a root-user on any of the machines
#                    with a mapped (decrypted) container or a passphrase on
#                    that machine can decrypt all other copies, breaking
#                    security

#   LUKS PASSPHRASE IS NOT THE MASTER KEY: The LUKS passphrase is not used in
#										   deriving the master key. It is used
#										   in decrypting a master key that is
#										   randomly selected on header
#										   creation. This means that if you
#										   create a new LUKS header on top of
#										   an old one with exactly the same
#										   parameters and exactly the same
#										   passphrase as the old one, it will
#										   still have a different master key
#										   and your data will be permanently
#										   lost. 

###### Setup Disk

# When setting up a device for use with LUKS & dm-crypt, it should first be
# wiped of previous data.
cat /dev/zero > /dev/sdb2


###### Create LUKS container

# Create LUKS container.
cryptsetup luksFormat /dev/sdb2

# Create LUKS container reading from /dev/random (not urandom).
cryptsetup luksFormat --use-random /dev/sdb2

# Create a LUKS container using aes-xts-plain64 with 512 bit key using sha512 hash
cryptsetup luksFormat --cipher aes-xts-plain64 --key-size 512 --hash sha512 /dev/sdb2


###### Open Container and map it

# Map the container.  It will be mapped to /dev/mapper/c1.
cryptsetup luksOpen /dev/sdb2 c1

# Now you need to wipe the container, make the filesystem, and mount it.
cat /dev/zero > /dev/mapper/c1
mke2fs /dev/mapper/c1
mount /dev/mapper/c1 /mnt


###### Inspect container

# Inspect container (this can be run any time after luksFormat).
cryptsetup luksDump /dev/sdb2

# Reports status for mapping (this can only be run after luksOpen).
cryptsetup status /dev/mapper/c1


#########################
######## OTHER ##########
#########################

# Here is summary of commands you will need to use to mount your root
# filesystem from a recovery CD, assuming your are running lvm on a luks
# partition.
modprobe dm-crypt
cryptsetup luksOpen /dev/sda3 mylvm
vgscan
vgchange --activate y
mkdir /mnt/oldroot
mount /dev/mapper/VolGroup00-volroot /mnt/oldroot
